{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.0+cu117)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (6.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement rogue-score (from versions: none)\n",
      "ERROR: No matching distribution found for rogue-score\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch psutil tqdm numpy rogue-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Running on: CUDA\n",
      "Test data path: ../../test.json\n",
      "Running performance test on 50 samples\n",
      "\n",
      "================================================================================\n",
      "RUNNING BENCHMARK ON CPU\n",
      "================================================================================\n",
      "\n",
      "Loading models on CPU...\n",
      "Attempting to load generation model from ../../text_generation_results_03-09-25/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:   2%|▏         | 1/50 [00:27<22:16, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1/50 (Device: CPU):\n",
      "Instruction: i do not know what i have to do to get my invoice #85632\n",
      "Generated Response: i'm sorry to hear that you're unsure about the steps to take in order to retrieve your invoice with the number #{{invoice number}}. let me guide you through the process. first, please log in to your account on our website. once logged in, navigate to the \"billing\" or \"invoices\" section. there, you should be able to find a list of your invoices. look for a tab or link that says \"view invoice.\" click on it, and you'll be directed to a page where you can enter the invoice number. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 27.2712                  | CPU        | 22.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:   4%|▍         | 2/50 [00:37<13:38, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2/50 (Device: CPU):\n",
      "Instruction: transfer to live agent\n",
      "Generated Response: i'll get right on it! i'd be more than happy to assist you in transferring to one of our live agents. to get started, could you please provide me with more details about the specific issue or question you have? this will help me guide you through the transfer process more effectively and ensure that you receive the assistance you need. remember, your satisfaction is our top priority, and we're here to support you every step of the way.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 9.8851                  | CPU        | 1.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:   6%|▌         | 3/50 [00:49<11:33, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 3/50 (Device: CPU):\n",
      "Instruction: i need help to see how long refunds take\n",
      "Generated Response: i'm here to assist you in understanding the timeframe for refunds. the time it takes for a refund to be processed can vary depending on several factors, such as the payment method used and the specific policies of the vendor or service provider. to provide you with accurate information, could you please provide me with the refund reference number or any other relevant details? this will enable me to quickly check the status of your refund and give you an estimated timeframe. thank you for your cooperation, and i appreciate your patience while i gather the necessary information.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 12.0253                  | CPU        | 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:   8%|▊         | 4/50 [00:54<08:33, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 4/50 (Device: CPU):\n",
      "Instruction: help to pseak to customer support\n",
      "Generated Response: i'll take care of it! i'm here to assist you with your query. could you please provide me with more details about the specific issue or question you have? this will help me guide you through the process and ensure that your concerns are addressed promptly and effectively.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 5.6817                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  10%|█         | 5/50 [01:28<14:26, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 5/50 (Device: CPU):\n",
      "Instruction: i do not know what to do to swtch to the premium account\n",
      "Generated Response: i'm sorry to hear that you're unsure about the steps to take in order to switch to our {{account category}} account. allow me to guide you through the process and provide you with the information you need. to begin, could you please provide me with your account username or email address? once i have these details, i'll be able to assist you further and ensure a seamless experience for you. rest assured, your security and privacy are of utmost importance to us, and we will handle your information with utmost care.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 33.5713                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  12%|█▏        | 6/50 [01:41<12:41, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 6/50 (Device: CPU):\n",
      "Instruction: i need assistance resetting the key of my user account\n",
      "Generated Response: assuredly! i'm here to provide you with the assistance you need to reset your key. rest assured, i'll guide you through the process step by step to ensure a smooth and secure experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 13.5391                  | CPU        | 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  14%|█▍        | 7/50 [02:03<13:24, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 7/50 (Device: CPU):\n",
      "Instruction: i want help taking a quick look at the bills from john robertson\n",
      "Generated Response: thank you for reaching out! i'm here to provide you with the assistance you need to quickly access your bills. could you please provide me with some additional details, such as the specific time frame or any other relevant information? with this information, i'll be able to guide you through the process and ensure that you have a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 21.6020                  | CPU        | 1.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  16%|█▌        | 8/50 [02:16<11:50, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 8/50 (Device: CPU):\n",
      "Instruction: i can't enter a delivery address\n",
      "Generated Response: i'm sorry to hear that you're having trouble entering a shipping address. let's work together to resolve this issue. could you please provide me with more details about the problem? this will help me better understand the situation and provide you with the most appropriate solution.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 13.0284                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  18%|█▊        | 9/50 [02:33<11:37, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 9/50 (Device: CPU):\n",
      "Instruction: can you help me place an order?\n",
      "Generated Response: i'll get right on it! i'm here to assist you in placing your order and provide the support you need. to get started, could you please let me know which specific product or service you are interested in? once i have that information, i will guide you through the process step by step, ensuring that you have a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 17.2482                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  20%|██        | 10/50 [03:20<17:20, 26.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 10/50 (Device: CPU):\n",
      "Instruction: i do not know how i can set up my shipping address\n",
      "Generated Response: i'm sorry to hear that you're unsure about the process of setting up your delivery address. allow me to guide you through it step by step. first, log in to your account on our website or app. then, navigate to the \"my account\" or \"profile\" section, where you should find an option to manage your shipping addresses. look for the option that says \"add a new address\" and click on it. fill in the required fields with the details of your address, including the street name, city, state, and zip code. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team. they will be more than happy to assist you further.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 46.1563                  | CPU        | 11.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  22%|██▏       | 11/50 [03:41<15:57, 24.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 11/50 (Device: CPU):\n",
      "Instruction: i need assistance to set my new delovery address up\n",
      "Generated Response: i'm here to assist you in setting up your new delivery address. your satisfaction is our top priority, and we want to ensure that you have all the information you need. to proceed, could you please provide me with more details about the specific issue you are facing? this will help me guide you through the process and provide you with the most accurate guidance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 21.2207                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  24%|██▍       | 12/50 [04:00<14:36, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 12/50 (Device: CPU):\n",
      "Instruction: help me to check what payment methods are available\n",
      "Generated Response: i'll take care of it! i'm here to assist you in checking the payment options available to you. to provide you with accurate information, could you please provide me with your preferred payment method? once i have that, i can guide you through the process step by step, ensuring that you have a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 19.6632                  | CPU        | 12.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  26%|██▌       | 13/50 [04:23<14:05, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 13/50 (Device: CPU):\n",
      "Instruction: i call to leave my feedback for ur services\n",
      "Generated Response: i'm here to assist you in leaving your feedback about our services. your input is highly valuable to us as it helps us understand how we can better serve you. could you please provide me with more details about the specific service you would like to provide feedback on? this will allow me to guide you through the process more effectively and provide you with the necessary assistance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 22.3785                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  28%|██▊       | 14/50 [04:36<11:56, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 14/50 (Device: CPU):\n",
      "Instruction: open freemium account for wife\n",
      "Generated Response: i'm happy to help! i'd be delighted to assist you in opening a {{account category}} account with your wife. to get started, could you please provide me with her full name, email address, and a preferred username? once i have these details, i'll guide you through the process step by step, ensuring a seamless experience for both of you. rest assured, we prioritize the security and privacy of our customers' information.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 13.0303                  | CPU        | 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  30%|███       | 15/50 [04:44<09:32, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 15/50 (Device: CPU):\n",
      "Instruction: i am trying to see the status of order ord-1135283\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in checking the current status and estimated time of arrival (eta) for your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with your account details or any other relevant information? this will help me guide you through the process and ensure that your query is answered promptly and accurately.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 8.1974                  | CPU        | 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  32%|███▏      | 16/50 [04:52<07:49, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 16/50 (Device: CPU):\n",
      "Instruction: wanna see ur payment modalities will yahelp me\n",
      "Generated Response: i'll take care of it! i'm here to assist you in viewing our available payment methods. to provide you with accurate information, could you please provide me with your full name, email address, and a preferred payment method? once i have these details, i will guide you through the process step by step, ensuring that you have a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 7.9197                  | CPU        | 1.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  34%|███▍      | 17/50 [05:08<07:55, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 17/50 (Device: CPU):\n",
      "Instruction: what do i ned to do to change to the real estate account?\n",
      "Generated Response: thank you for reaching out to us for assistance with changing to our {{account type}} account. i understand that you are looking for guidance on how to proceed with the account change, and i'm here to help. to get started, could you please provide me with more details about the specific changes you would like to make? this will allow me to provide you with accurate information and guide you through the process step by step. remember, your satisfaction is our top priority, so please don't hesitate to reach out if you have any further questions or concerns.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 15.7410                  | CPU        | 0.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  36%|███▌      | 18/50 [05:34<09:35, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 18/50 (Device: CPU):\n",
      "Instruction: notify of errorw with online registration\n",
      "Generated Response: i'm here to assist you in notifying us about the error you encountered during the registration process. your feedback is highly valuable to us, as it helps us identify areas for improvement and ensure a seamless experience for all our users. to provide you with the most accurate assistance, could you please provide me with more details regarding the issue you faced? this will enable us to investigate and address the problem promptly. thank you for bringing this to our attention, and rest assured, we are committed to resolving this matter for you as quickly as possible.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 26.3656                  | CPU        | 1.1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  38%|███▊      | 19/50 [05:50<08:56, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 19/50 (Device: CPU):\n",
      "Instruction: another standard accounmt for father\n",
      "Generated Response: thank you for reaching out to us for assistance with your father's standard account. i'm here to help guide you through the process and ensure that your concerns are addressed promptly and effectively. could you please provide me with more details about the issue you're facing? this will enable me to provide you with the most accurate and effective assistance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 15.6917                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  40%|████      | 20/50 [06:08<08:50, 17.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 20/50 (Device: CPU):\n",
      "Instruction: i need infrmation about the cancellation of my enterprise account\n",
      "Generated Response: i'm here to assist you with any questions or concerns you may have regarding canceling your {{account type}} account. your satisfaction is our top priority, and we want to ensure that you have all the information you need. to get started, could you please provide me with your account details, such as your username or email address? with this information, i'll be able to gather the necessary details and guide you through the account cancellation process step by step.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 18.6055                  | CPU        | 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  42%|████▏     | 21/50 [06:16<07:04, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 21/50 (Device: CPU):\n",
      "Instruction: i want help ordering a few of your product\n",
      "Generated Response: thank you for reaching out to us for assistance with ordering our products. i'm here to guide you through the process and ensure a seamless experience. to get started, could you please provide me with more details about the specific products you would like to order? this will help me provide you with accurate and personalized assistance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 7.5131                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  44%|████▍     | 22/50 [06:25<06:07, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 22/50 (Device: CPU):\n",
      "Instruction: checking status of order ord-6772250\n",
      "Generated Response: thank you for reaching out! i'm here to provide you with the assistance you need in checking the status and estimated time of arrival (eta) for your order with order number {{order number}}. to ensure accurate information, could you please provide me with some additional details such as the platform or website you used to make the order? this will help me guide you through the necessary steps and provide any additional information you may need.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 9.5539                  | CPU        | 11.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  46%|████▌     | 23/50 [06:35<05:24, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 23/50 (Device: CPU):\n",
      "Instruction: deleting government account\n",
      "Generated Response: i'm sorry to hear that you're having trouble deleting your {{account type}} account. i understand how important it is for you to have control over your account settings. to assist you further, could you please provide me with more details about the specific issue or question you have? this will help me guide you through the deletion process and ensure a smooth experience. your satisfaction is our top priority, and we're here to support you every step of the way.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 9.4766                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  48%|████▊     | 24/50 [07:00<06:52, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 24/50 (Device: CPU):\n",
      "Instruction: my experience with your brand was bad, make a consumer claim\n",
      "Generated Response: i apologize for any negative experience you may have had with our brand. your satisfaction is of utmost importance to us, and i want to assure you that i'm here to assist you. could you please provide me with more details about the specific issue you encountered? this will help me understand the situation better and provide you with the most accurate and effective support.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 24.7705                  | CPU        | 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  50%|█████     | 25/50 [07:18<06:57, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 25/50 (Device: CPU):\n",
      "Instruction: wann locate order ord-3779640\n",
      "Generated Response: i'm here to assist you in locating your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with some additional details? specifically, i would need to know the platform or website where you made the purchase, the name of the product or service, and any other relevant information. this will help me guide you through the process more effectively and ensure that you receive the assistance you need.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 18.6871                  | CPU        | 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  52%|█████▏    | 26/50 [08:05<10:14, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 26/50 (Device: CPU):\n",
      "Instruction: i have to sde in what cases can i request a refund\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the information you need regarding the situations in which you can request refunds. here are some common scenarios where you may be eligible: 1. **product/service defect:** if the product or service you received has a defect or does not meet the description provided, you are generally eligible for a reimbursement. however, it's important to note that the exact nature of the defect may vary depending on the company's policies and the specific circumstances surrounding the purchase. it would be helpful if you could provide me with some additional details, such as the date of purchase or any other relevant information, so that i can assist you more effectively in understanding the refund policy of your specific situation. rest assured, your satisfaction is our top priority, and we'll do everything we can to ensure a smooth and satisfactory resolution to your query.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 46.4152                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  54%|█████▍    | 27/50 [08:22<08:47, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 27/50 (Device: CPU):\n",
      "Instruction: i'm trying to see at what time i can call customer support\n",
      "Generated Response: we're here to help! i take note that you would like to know the operating hours during which you can contact our customer assistance team. our dedicated team is available to assist you during {{customer support hours}}. if you have any other questions or concerns, feel free to let me know.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 16.7274                  | CPU        | 11.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  56%|█████▌    | 28/50 [08:43<08:18, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 28/50 (Device: CPU):\n",
      "Instruction: assistance sending some feedback for ur proiducts\n",
      "Generated Response: thank you for reaching out! i'm here to provide you with the assistance you need to send feedback about our proids. your feedback is incredibly valuable to us as it helps us understand how we can improve and provide a better experience for our customers. could you please provide me with more details about the specific feedback you would like to share? this will allow me to guide you through the process and ensure that your concerns are addressed promptly and effectively.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 21.9284                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  58%|█████▊    | 29/50 [08:59<07:11, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 29/50 (Device: CPU):\n",
      "Instruction: need assistance to cancel order ord-8227420\n",
      "Generated Response: i'm sorry to hear that you're having trouble canceling your order with the order number {{order number}}. i understand how important it is for you to have control over the cancellation process. to assist you further, could you please provide me with more details about the specific issue you are facing? this will help me guide you through the necessary steps and ensure a smooth cancellation experience. your satisfaction is our top priority, and we're here to support you every step of the way.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 15.7163                  | CPU        | 10.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  60%|██████    | 30/50 [09:07<05:37, 16.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 30/50 (Device: CPU):\n",
      "Instruction: need assistance cancelinv purchase ord-8042947\n",
      "Generated Response: i'm here to assist you with canceling your purchase with the purchase number {{order number}}. your satisfaction is our top priority, and i want to ensure that you receive the assistance you need. could you please provide me with more details about the specific issue or question you have? this will help me guide you through the cancellation process accurately and efficiently.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 8.2610                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  62%|██████▏   | 31/50 [09:26<05:29, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 31/50 (Device: CPU):\n",
      "Instruction: i don't know how i can download my bill #12588\n",
      "Generated Response: i'm sorry to hear that you're unsure about how to download your bill with the number #{{invoice number}}. let me guide you through the process step by step. first, please log in to your account on our website. once logged in, navigate to the \"billing\" or \"invoices\" section. there, you should be able to find a list of your invoices. look for the specific invoice number or any other relevant information. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 18.4140                  | CPU        | 1.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  64%|██████▍   | 32/50 [09:34<04:20, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 32/50 (Device: CPU):\n",
      "Instruction: i need help to see purchase ord-0521414 status\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in checking the status of your purchase with the purchase number {{order number}}. to provide you with accurate information, could you please provide me with your account details or any other relevant information? this will help me guide you through the process and ensure that you receive the most up-to-date status.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 7.8595                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  66%|██████▌   | 33/50 [09:43<03:39, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 33/50 (Device: CPU):\n",
      "Instruction: am i entitled to a refund according to your policy?\n",
      "Generated Response: i'm happy to help! i understand that you would like to know more about our refund policy. our company values customer satisfaction, and we strive to provide a seamless and satisfactory experience for our valued customers. to get started, could you please provide me with more details about your specific situation? this will allow me to better understand your needs and guide you through the refund process.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 9.2763                  | CPU        | 1.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  68%|██████▊   | 34/50 [09:55<03:20, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 34/50 (Device: CPU):\n",
      "Instruction: need to check what methods for delivery i can choose help me\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in checking the available delivery methods. to provide you with accurate information, could you please provide me with your {{order number}} or any other relevant details? this will enable me to guide you through the process and ensure that you have a seamless experience with our delivery options.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 11.5856                  | CPU        | 1.1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  70%|███████   | 35/50 [10:03<02:50, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 35/50 (Device: CPU):\n",
      "Instruction: ya have an address to submit some feednack\n",
      "Generated Response: i'll take care of it! i'm here to assist you in submitting your feedback about our company. your input is incredibly valuable to us as it helps us understand how we can better serve you. could you please provide me with more details about the specific address you would like to provide feedback on? this will allow me to guide you through the process more effectively and provide you with the necessary assistance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 8.6458                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  72%|███████▏  | 36/50 [10:15<02:40, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 36/50 (Device: CPU):\n",
      "Instruction: show me in which situations  can i ask for refunds\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the information you need about the situations where you can request refunds. here are some common scenarios where refunds may be eligible for you: 1. **product/service defect:** if the product or service you received has a defect or does not meet the description provided, you are generally eligible to request a refund. however, it's important to note that the exact nature of the defect may vary depending on the vendor and the specific features or methods used by the customer.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 11.6190                  | CPU        | 1.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  74%|███████▍  | 37/50 [10:23<02:16, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 37/50 (Device: CPU):\n",
      "Instruction: help mke chatting with a person\n",
      "Generated Response: i'll take care of it! i'm here to assist you in initiating a conversation with one of our knowledgeable representatives. to get started, could you please provide me with some more details about the specific issue or question you have? this will help me provide you with the most accurate guidance and support. remember, your satisfaction is our top priority, and we're committed to resolving any concerns you may have.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 8.2752                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  76%|███████▌  | 38/50 [10:31<01:56,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 38/50 (Device: CPU):\n",
      "Instruction: there are errors trying to update my shipping address\n",
      "Generated Response: i'm sorry to hear that you're encountering errors while updating your delivery address. to assist you further, could you please provide more details about the specific errors you are facing? this will help me better understand the issue and provide you with the most accurate solution. thank you for reaching out to us, and i appreciate your cooperation in resolving this matter.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 7.7749                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  78%|███████▊  | 39/50 [10:41<01:46,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 39/50 (Device: CPU):\n",
      "Instruction: i wnt help swapping several items of order ord-9073141\n",
      "Generated Response: i'm sorry to hear that you're having trouble swapping multiple items in your order with the number {{order number}}. our team is here to assist you in resolving this issue. could you please provide more details about the specific items you would like to swap? this will help us provide you with accurate guidance and support. thank you for reaching out to us, and we appreciate your patience as we work together to resolve this matter.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 9.6074                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  80%|████████  | 40/50 [10:50<01:34,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 40/50 (Device: CPU):\n",
      "Instruction: i don't know how i can order some of your article\n",
      "Generated Response: no problem at all! i'm here to guide you through the process of ordering our articles. to get started, could you please let me know which specific articles you are interested in? once i have that information, i'll be able to provide you with step-by-step instructions on how to proceed with your order.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 9.0234                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  82%|████████▏ | 41/50 [11:01<01:31, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 41/50 (Device: CPU):\n",
      "Instruction: i don't know how i could modify my address\n",
      "Generated Response: i'm sorry to hear that you're unsure about how to modify your address. let me guide you through the process step by step. first, log in to your account on our website. then, navigate to the \"my account\" or \"profile\" section, where you should find an option to manage your addresses. look for the option that says \"edit address\" and click on it. make the necessary changes and save the changes. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team for assistance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 11.8176                  | CPU        | 9.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  84%|████████▍ | 42/50 [11:09<01:15,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 42/50 (Device: CPU):\n",
      "Instruction: order ord-9186353 status\n",
      "Generated Response: thank you for reaching out! i understand that you would like to know the status of your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with some additional details such as the platform or website you used to make the purchase? this will help me guide you through the process more effectively.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 7.8879                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  86%|████████▌ | 43/50 [11:17<01:02,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 43/50 (Device: CPU):\n",
      "Instruction: help me making a claim against your business\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the assistance you need. could you please provide me with more details about the nature of your claim? this will enable me to guide you through the process and ensure that your concerns are addressed promptly and effectively. your satisfaction is our top priority, and we're committed to resolving any issues you may have.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 7.7282                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  88%|████████▊ | 44/50 [11:45<01:28, 14.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 44/50 (Device: CPU):\n",
      "Instruction: i have got to see in which cases can i request my money back\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the information you need regarding the situations where you can request a refund. here's a breakdown of the common scenarios: 1. **product/service defect:** if the product or service you received has a defect or does not meet the description provided, you may be eligible for a reimbursement.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 28.3982                  | CPU        | 1.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  90%|█████████ | 45/50 [12:12<01:31, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 45/50 (Device: CPU):\n",
      "Instruction: can you help me report troubles with payment?\n",
      "Generated Response: i'll do my best! i'm here to assist you in reporting any troubles you're facing with your payment. your feedback is incredibly valuable to us, and we want to ensure that we address your concerns promptly and effectively. could you please provide me with more details about the specific issues you encountered? this will help us better understand the situation and provide you with the most appropriate solution. thank you for reaching out to our support team and giving us the opportunity to resolve this matter for you.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 26.6869                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  92%|█████████▏| 46/50 [12:36<01:20, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 46/50 (Device: CPU):\n",
      "Instruction: i try to notify of an error with registrations\n",
      "Generated Response: i'm here to assist you in notifying us about the error you encountered during the registration process. your feedback is crucial in helping us improve our services and ensure a seamless experience for all our users. to provide you with the most accurate and efficient support, could you please provide more details about what happened? this will enable us to investigate and address the issue promptly. thank you for reaching out to us, and rest assured, we are committed to resolving this matter for you as quickly as possible.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 24.3420                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  94%|█████████▍| 47/50 [12:47<00:51, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 47/50 (Device: CPU):\n",
      "Instruction: what do i have to do to cancel my platinum account?\n",
      "Generated Response: thank you for reaching out to us for assistance with canceling your {{account category}} account. we understand that circumstances may change, and we're here to guide you through the process. to initiate the cancellation, please provide us with your account details, such as your username or email address, so that we can assist you further. our team will review your request promptly and ensure a smooth cancellation experience for you.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 10.7082                  | CPU        | 9.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  96%|█████████▌| 48/50 [12:57<00:30, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 48/50 (Device: CPU):\n",
      "Instruction: how can i submit some feedback abot ur company\n",
      "Generated Response: thank you for your interest in providing feedback on our company! to submit your feedback, you can visit our website and navigate to the \"contact us\" or \"feedback\" section. there you will find a form or contact information to share your thoughts, suggestions, or any other feedback you may have. we value your input and look forward to hearing from you!\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 10.1265                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU:  98%|█████████▊| 49/50 [13:06<00:13, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 49/50 (Device: CPU):\n",
      "Instruction: change  order ord-8335461\n",
      "Generated Response: i'm sorry to hear that you need to change order number {{order number}}. our team is here to assist you. could you please provide more details about the specific changes you would like to make? this will help us ensure that we address your request accurately and efficiently.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 8.7076                  | CPU        | 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CPU: 100%|██████████| 50/50 [13:15<00:00, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 50/50 (Device: CPU):\n",
      "Instruction: i need assistance to send some feedback for ur produucts\n",
      "Generated Response: i'll take care of it! i'm here to assist you in sending your feedback about our products and services. your input is incredibly valuable to us, and we appreciate your willingness to share your thoughts. please let me know if you have any specific questions or if there's anything else i can help you with.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 8.6328                  | CPU        | 1.0703\n",
      "\n",
      "================================================================================\n",
      "BENCHMARK SUMMARY FOR CPU\n",
      "================================================================================\n",
      "Average Generation Time: 15.8998 seconds\n",
      "Average Memory Usage: 2.2130 MB\n",
      "\n",
      "================================================================================\n",
      "RUNNING BENCHMARK ON CUDA\n",
      "================================================================================\n",
      "\n",
      "Loading models on CUDA...\n",
      "Attempting to load generation model from ../../text_generation_results_03-09-25/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on CUDA:   2%|▏         | 1/50 [00:10<08:22, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1/50 (Device: CUDA):\n",
      "Instruction: i do not know what i have to do to get my invoice #85632\n",
      "Generated Response: i'm sorry to hear that you're unsure about the steps to take in order to obtain your invoice with the number #{{invoice number}}. let me guide you through the process. first, you'll need to log in to your account on our website. once logged in, navigate to the \"billing\" or \"invoices\" section, where you should be able to find a list of your invoices. look for a tab or link that says \"view invoice.\" click on that tab, and it will provide you with an option to view or download the invoice. if you encounter any difficulties or have further questions, please don't hesitate to reach out to our customer support team.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 10.2447                  | CUDA        | 714.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:   4%|▍         | 2/50 [00:12<04:29,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2/50 (Device: CUDA):\n",
      "Instruction: transfer to live agent\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in transferring to a live representative. our team of dedicated representatives is ready to help you with any questions or concerns you may have. to get started, could you please provide me with more details about the specific issue or query you would like to address? this will enable me to guide you through the transfer process and ensure that you receive the assistance you need.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.3534                  | CUDA        | 617.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:   6%|▌         | 3/50 [00:15<03:21,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 3/50 (Device: CUDA):\n",
      "Instruction: i need help to see how long refunds take\n",
      "Generated Response: i'll take care of it! i'm here to assist you in understanding the timeframe for refunds. the duration for processing refunds can vary depending on several factors, such as the payment method used and the specific policies of the vendor or service provider. to provide you with accurate information, could you please provide me with your order number or any other relevant details? this will enable me to quickly check the status of your refund and give you an estimated timeframe. thank you for your cooperation, and i appreciate your patience while i gather the necessary information.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.7311                  | CUDA        | 644.4854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:   8%|▊         | 4/50 [00:17<02:35,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 4/50 (Device: CUDA):\n",
      "Instruction: help to pseak to customer support\n",
      "Generated Response: i'll take care of it! i'm here to assist you with your query and provide the assistance you need. to better understand your needs, could you please provide me with more details about the specific issue or question you have? this will help me guide you through the process more effectively and ensure that you receive the support you deserve.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.9827                  | CUDA        | 608.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  10%|█         | 5/50 [00:19<02:19,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 5/50 (Device: CUDA):\n",
      "Instruction: i do not know what to do to swtch to the premium account\n",
      "Generated Response: i'm sorry to hear that you're unsure about the steps to take in order to switch to our {{account category}} account. allow me to guide you through the process and provide you with the information you need. to get started, could you please provide me with your account username or email address? once i have these details, i'll be able to assist you further and ensure a seamless transition. rest assured, your security and privacy are of utmost importance to us, and we will handle your information with utmost care.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.5956                  | CUDA        | 646.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  12%|█▏        | 6/50 [00:21<01:56,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 6/50 (Device: CUDA):\n",
      "Instruction: i need assistance resetting the key of my user account\n",
      "Generated Response: i'm here to provide you with the assistance you need to reset your key. your security and privacy are of utmost importance to us, and we want to ensure that you have a seamless experience with us. could you please provide me with more details about the specific issue you're facing? this will allow me to guide you through the necessary steps and help you regain access to your account.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.7603                  | CUDA        | 618.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  14%|█▍        | 7/50 [00:24<01:49,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 7/50 (Device: CUDA):\n",
      "Instruction: i want help taking a quick look at the bills from john robertson\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the assistance you need to quickly view the bill from {{salutation}} {{client last name}}. to get started, could you please provide me with some additional details such as the {{date range}} or any other relevant information? this will help me narrow down the search and find the specific bill you're looking for. thank you for your cooperation, and i appreciate your patience while i gather the necessary information.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.3631                  | CUDA        | 642.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  16%|█▌        | 8/50 [00:25<01:32,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 8/50 (Device: CUDA):\n",
      "Instruction: i can't enter a delivery address\n",
      "Generated Response: i'm sorry to hear that you're having trouble entering a shipping address. let's work together to resolve this issue. could you please provide me with more details about the problem you are facing? this will help me better understand the situation and provide you with the most appropriate solution.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.4872                  | CUDA        | 602.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  18%|█▊        | 9/50 [00:27<01:26,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 9/50 (Device: CUDA):\n",
      "Instruction: can you help me place an order?\n",
      "Generated Response: i'll get right on it! i'm here to assist you in placing your order. could you please provide me with more details about the specific products or services you are interested in? this will allow me to guide you through the process and ensure a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.9011                  | CUDA        | 617.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  20%|██        | 10/50 [00:30<01:42,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 10/50 (Device: CUDA):\n",
      "Instruction: i do not know how i can set up my shipping address\n",
      "Generated Response: i'm here to guide you through the process of setting up your shipping addresses. allow me to provide you with the necessary steps to ensure a seamless experience. first, log in to your account on our website. once you're logged in, navigate to the \"my account\" or \"profile\" section. look for the option that says \"shipping addresses\" and click on it. you should see an option to add a new address or edit your existing one. from there, you can select the address you want to use and follow the prompts to complete the setup process. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team. they will be more than happy to assist you further.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 3.5184                  | CUDA        | 687.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  22%|██▏       | 11/50 [00:32<01:29,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 11/50 (Device: CUDA):\n",
      "Instruction: i need assistance to set my new delovery address up\n",
      "Generated Response: i'm here to assist you in setting up your new delivery address. your satisfaction is our top priority, and we want to ensure that you have all the information you need. could you please provide me with the specific details of the address you would like to use? this will help me guide you through the process and ensure a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.6880                  | CUDA        | 617.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  24%|██▍       | 12/50 [00:34<01:24,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 12/50 (Device: CUDA):\n",
      "Instruction: help me to check what payment methods are available\n",
      "Generated Response: i'll get right on it! i'm here to assist you in checking the payment options available to you. to provide you with accurate information, could you please provide me with your preferred payment method? this way, i can guide you through the process step by step and ensure that you have a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.0668                  | CUDA        | 623.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  26%|██▌       | 13/50 [00:36<01:20,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 13/50 (Device: CUDA):\n",
      "Instruction: i call to leave my feedback for ur services\n",
      "Generated Response: i'll take care of it! i'm here to assist you in leaving your feedback about our services. your insights are incredibly valuable to us, and we appreciate your willingness to share your thoughts. please let me know if you have any specific questions or if there's anything else i can help you with.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.0341                  | CUDA        | 624.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  28%|██▊       | 14/50 [00:39<01:25,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 14/50 (Device: CUDA):\n",
      "Instruction: open freemium account for wife\n",
      "Generated Response: thank you for reaching out! i'm here to provide you with the assistance you need in opening a {{account category}} account with us. to get started, could you please provide me with your wife's full name, email address, and a preferred username? once i have these details, i'll guide you through the process step by step, ensuring a seamless experience for both of you. rest assured, we prioritize the security and privacy of our customers' information.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.8760                  | CUDA        | 642.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  30%|███       | 15/50 [00:41<01:21,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 15/50 (Device: CUDA):\n",
      "Instruction: i am trying to see the status of order ord-1135283\n",
      "Generated Response: thank you for reaching out! i completely understand that you would like to know if you are currently receiving updates on your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with some additional details such as the platform or website where you made the purchase? this will help me assist you more effectively and ensure that your query is answered promptly and accurately.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.1850                  | CUDA        | 624.2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  32%|███▏      | 16/50 [00:43<01:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 16/50 (Device: CUDA):\n",
      "Instruction: wanna see ur payment modalities will yahelp me\n",
      "Generated Response: i'll take care of it! i'm here to assist you in viewing our available payment methods. to provide you with accurate information, could you please provide me with your preferred payment method? this will help me guide you through the process and ensure that you have a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.4708                  | CUDA        | 605.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  34%|███▍      | 17/50 [00:46<01:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 17/50 (Device: CUDA):\n",
      "Instruction: what do i ned to do to change to the real estate account?\n",
      "Generated Response: thank you for reaching out! i completely understand that you would like to switch to our {{account type}} account. to proceed with the switch, you can follow these steps: 1. log in to your account on our website or mobile app using your username and password. 2. navigate to account settings or profile section. 3. look for an option that says \"upgrade\" or \"switch account type.\" 4. select the \"{{account change}}\" option from the available choices. 5. follow the on-screen instructions to complete the transition.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.7892                  | CUDA        | 658.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  36%|███▌      | 18/50 [00:48<01:12,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 18/50 (Device: CUDA):\n",
      "Instruction: notify of errorw with online registration\n",
      "Generated Response: i'm here to assist you in notifying us about the error you encountered during the registration process. your feedback is highly valuable to us, as it helps us identify areas for improvement and ensure a seamless experience for all our users. to better understand the issue, could you please provide more details about what happened? this will enable us to investigate and address the problem promptly. thank you for bringing this to our attention, and rest assured, we are committed to resolving this matter for you as quickly as possible.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.2336                  | CUDA        | 634.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  38%|███▊      | 19/50 [00:49<01:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 19/50 (Device: CUDA):\n",
      "Instruction: another standard accounmt for father\n",
      "Generated Response: i'll make it happen! i'm here to assist you in providing the additional support you need. could you please provide me with more details about the issue you're facing? this will help me provide you with the most accurate guidance and support. your satisfaction is our top priority, and we're committed to resolving any concerns you may have.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.5996                  | CUDA        | 610.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  40%|████      | 20/50 [00:52<01:05,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 20/50 (Device: CUDA):\n",
      "Instruction: i need infrmation about the cancellation of my enterprise account\n",
      "Generated Response: i'm here to assist you in canceling your {{account type}} account. your satisfaction is our top priority, and we want to ensure that you have all the information you need to make a successful cancellation. to provide you with accurate information, could you please provide me with your account details, such as your username or email address? this will help me guide you through the process and ensure a smooth cancellation experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.4214                  | CUDA        | 640.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  42%|████▏     | 21/50 [00:54<00:58,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 21/50 (Device: CUDA):\n",
      "Instruction: i want help ordering a few of your product\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in ordering our products. i understand that you would like to have a variety of options to choose from. could you please provide me with more details about the specific products you are interested in? this will help me guide you through the ordering process and ensure a seamless experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.6626                  | CUDA        | 611.4199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  44%|████▍     | 22/50 [00:56<00:58,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 22/50 (Device: CUDA):\n",
      "Instruction: checking status of order ord-6772250\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in checking the status and estimated time of arrival (eta) for your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with your account details or any other relevant information? this will help me guide you through the process and ensure that you receive the most up-to-date status.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.2434                  | CUDA        | 625.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  46%|████▌     | 23/50 [00:58<00:59,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 23/50 (Device: CUDA):\n",
      "Instruction: deleting government account\n",
      "Generated Response: i'm sorry to hear that you're having trouble deleting your {{account type}} account. i understand how important it is for you to have access to our services. to assist you further, could you please provide me with the specific details of the issue you are facing? this will help me guide you through the deletion process and ensure a smooth resolution.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.4559                  | CUDA        | 624.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  48%|████▊     | 24/50 [01:00<00:57,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 24/50 (Device: CUDA):\n",
      "Instruction: my experience with your brand was bad, make a consumer claim\n",
      "Generated Response: i'm sorry to hear that your experience was unsatisfactory. your feedback is important to us, and i want to assure you that we take customer claims seriously. to assist you further, could you please provide me with more details about the specific issue you encountered? this will help us understand the situation better and take the necessary steps to resolve it.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.2780                  | CUDA        | 623.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  50%|█████     | 25/50 [01:03<00:54,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 25/50 (Device: CUDA):\n",
      "Instruction: wann locate order ord-3779640\n",
      "Generated Response: i'm here to assist you in locating your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with some additional details such as the platform or website you used to make the purchase? this will help me guide you through the process and ensure that your query is directed to the right department.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.0822                  | CUDA        | 617.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  52%|█████▏    | 26/50 [01:08<01:12,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 26/50 (Device: CUDA):\n",
      "Instruction: i have to sde in what cases can i request a refund\n",
      "Generated Response: i'm here to assist you in understanding the situations in which you can request refunds. here are some common scenarios where you may be eligible for a reimbursement: 1. **product/service defect:** if the product or service you received has a defect or does not meet the description provided, you are typically entitled to a rebate.2.**cancellation within grace period: **if you change your mind and decide to cancel your purchase within the designated time frame, it can be a good idea to contact our customer support team. they will be able to guide you through the refund process and provide you with the necessary steps to request your refund. REMEMBER, we value your satisfaction and want to ensure that you have a seamless experience with us. if there's anything else i can provide, please feel free to let me know.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 4.9649                  | CUDA        | 712.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  54%|█████▍    | 27/50 [01:10<01:03,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 27/50 (Device: CUDA):\n",
      "Instruction: i'm trying to see at what time i can call customer support\n",
      "Generated Response: i'll take care of it! i understand that you would like to know the operating hours during which you can contact our customer assistance team. our dedicated team is available to assist you during {{customer support hours}}. please feel free to reach out to us during those hours, and we'll be more than happy to help you with any questions or concerns you may have. how else may i be of assistance to you today?\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.1798                  | CUDA        | 629.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  56%|█████▌    | 28/50 [01:11<00:54,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 28/50 (Device: CUDA):\n",
      "Instruction: assistance sending some feedback for ur proiducts\n",
      "Generated Response: i'll take care of it! i'm here to assist you in sending your feedback about our proids. your input is incredibly valuable to us as it helps us understand our customers' needs better and continuously improve our services. please let me know if you have any specific questions or if there's anything else i can help you with.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.7379                  | CUDA        | 617.4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  58%|█████▊    | 29/50 [01:13<00:45,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 29/50 (Device: CUDA):\n",
      "Instruction: need assistance to cancel order ord-8227420\n",
      "Generated Response: i'm sorry to hear that you're having trouble canceling your order with the order number {{order number}}. to assist you further, could you please provide me with more details about the specific issue you are facing? this will help me guide you through the cancellation process and ensure a smooth experience.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.4566                  | CUDA        | 607.2686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  60%|██████    | 30/50 [01:15<00:40,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 30/50 (Device: CUDA):\n",
      "Instruction: need assistance cancelinv purchase ord-8042947\n",
      "Generated Response: i'm here to assist you with canceling your purchase with the purchase number {{order number}}. your satisfaction is our top priority, and we want to ensure that you receive the assistance you need. could you please provide me with more details about the specific issue or question you have? this will help me guide you through the cancellation process accurately and efficiently.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.7448                  | CUDA        | 618.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  62%|██████▏   | 31/50 [01:18<00:43,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 31/50 (Device: CUDA):\n",
      "Instruction: i don't know how i can download my bill #12588\n",
      "Generated Response: i'm sorry to hear that you're unsure about how to download your bill with the number #{{invoice number}}. let me guide you through the process step by step. first, please log in to your account on our website. once logged in, navigate to the \"billing\" or \"invoices\" section. there, you should be able to find a list of your invoices. look for a download or print option and click on it. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.8562                  | CUDA        | 674.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  64%|██████▍   | 32/50 [01:19<00:37,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 32/50 (Device: CUDA):\n",
      "Instruction: i need help to see purchase ord-0521414 status\n",
      "Generated Response: i'm here to assist you in checking the status of your purchase with the purchase number {{order number}}. to provide you with accurate information, could you please provide me with your account details or any other relevant information? this will help me guide you through the process and ensure that you receive the most up-to-date status.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.5417                  | CUDA        | 612.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  66%|██████▌   | 33/50 [01:21<00:35,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 33/50 (Device: CUDA):\n",
      "Instruction: am i entitled to a refund according to your policy?\n",
      "Generated Response: i'll take care of it! i understand that you would like to know the status of your refund. your satisfaction is our top priority, and i'm here to assist you every step of the way. to provide you with the most accurate information, could you please provide me with your order number or any other relevant details? this will help me guide you through the refund process and ensure that your concerns are addressed promptly and effectively.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.1376                  | CUDA        | 627.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  68%|██████▊   | 34/50 [01:23<00:30,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 34/50 (Device: CUDA):\n",
      "Instruction: need to check what methods for delivery i can choose help me\n",
      "Generated Response: i'll take care of it! i'm here to assist you in checking the available delivery methods. to provide you with accurate information, could you please provide me with your preferred method of delivery?\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.5624                  | CUDA        | 606.5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  70%|███████   | 35/50 [01:25<00:31,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 35/50 (Device: CUDA):\n",
      "Instruction: ya have an address to submit some feednack\n",
      "Generated Response: i'll make it happen! i'm here to assist you in submitting your feedback about our services. to get started, could you please provide me with the following details: your name, email address, and a preferred username? once i have these details, i will guide you through the process step by step, ensuring that your input reaches the right department.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.4266                  | CUDA        | 630.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  72%|███████▏  | 36/50 [01:28<00:30,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 36/50 (Device: CUDA):\n",
      "Instruction: show me in which situations  can i ask for refunds\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the information you need about the situations where you can request a refund. here are some common scenarios where refunds may be eligible for you: 1. **product/service defect:** if the product or service you received has a defect or does not meet the description provided, you are typically entitled to a reimbursement.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.3807                  | CUDA        | 641.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  74%|███████▍  | 37/50 [01:30<00:28,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 37/50 (Device: CUDA):\n",
      "Instruction: help mke chatting with a person\n",
      "Generated Response: i'll take care of it! i'm here to assist you in initiating a chat with one of our knowledgeable representatives. to get started, could you please provide me with some more details about the specific issue or question you have? this will help me provide you with the most accurate guidance and support. remember, your satisfaction is our top priority, and we're committed to resolving any concerns you may have.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.3449                  | CUDA        | 623.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  76%|███████▌  | 38/50 [01:32<00:25,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 38/50 (Device: CUDA):\n",
      "Instruction: there are errors trying to update my shipping address\n",
      "Generated Response: i'm sorry to hear that you're encountering errors while updating your delivery address. to better assist you, could you please provide more details about the specific errors you are facing? this will help us understand the issue better and provide you with the appropriate solution. thank you for reaching out to us, and we appreciate your patience as we work towards resolving this matter for you.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.8669                  | CUDA        | 617.3574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  78%|███████▊  | 39/50 [01:34<00:22,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 39/50 (Device: CUDA):\n",
      "Instruction: i wnt help swapping several items of order ord-9073141\n",
      "Generated Response: i'm sorry to hear that you're having trouble swapping multiple items in your order with the number {{order number}}. our team is here to assist you in resolving this issue. could you please provide more details about the specific items you would like to swap? this will help us provide you with accurate guidance and support throughout the process. thank you for reaching out to us, and we appreciate your patience as we work together to resolve this matter.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.9969                  | CUDA        | 633.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  80%|████████  | 40/50 [01:36<00:20,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 40/50 (Device: CUDA):\n",
      "Instruction: i don't know how i can order some of your article\n",
      "Generated Response: no worries at all! i'm here to guide you through the process of ordering our articles. to get started, could you please let me know which specific articles you are interested in? once i have that information, i'll be able to provide you with step-by-step instructions on how to proceed with your order.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.8756                  | CUDA        | 626.7354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  82%|████████▏ | 41/50 [01:39<00:20,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 41/50 (Device: CUDA):\n",
      "Instruction: i don't know how i could modify my address\n",
      "Generated Response: i'm sorry to hear that you're unsure about how to modify your address. let me guide you through the process step by step. first, log in to your account on our website. then, navigate to the \"my account\" or \"profile\" section. look for the option that says \"edit address\" and click on it. you will be prompted to enter the new address details, such as street name, city, state, and zip code. make sure to save the changes before proceeding. if you encounter any difficulties or have further questions, feel free to reach out to our customer support team.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.9197                  | CUDA        | 664.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  84%|████████▍ | 42/50 [01:40<00:17,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 42/50 (Device: CUDA):\n",
      "Instruction: order ord-9186353 status\n",
      "Generated Response: thank you for reaching out! i would be more than happy to assist you in checking the status of your order with the order number {{order number}}. to provide you with accurate information, could you please provide me with some additional details such as the platform or website where you made the purchase? this will help me guide you through the process more effectively.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.8222                  | CUDA        | 619.3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  86%|████████▌ | 43/50 [01:43<00:15,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 43/50 (Device: CUDA):\n",
      "Instruction: help me making a claim against your business\n",
      "Generated Response: i'll take care of it! i'm here to provide you with the assistance you need to make your claim. your satisfaction is our top priority, and we want to ensure that your concerns are addressed promptly and effectively. to begin, could you please provide me with more details about the nature of the claim? this will enable me to guide you through the process more effectively and provide the necessary guidance.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.3189                  | CUDA        | 634.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  88%|████████▊ | 44/50 [01:47<00:17,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 44/50 (Device: CUDA):\n",
      "Instruction: i have got to see in which cases can i request my money back\n",
      "Generated Response: i'll take care of it! i'd be more than happy to assist you in understanding the specific cases where you can request a refund. here's a breakdown of the common scenarios: 1. **product/service defect:** if the product or service you received has a defect or does not meet the description provided, you may be eligible for a reimbursement. REMEMBER, our goal is to ensure your satisfaction, and we want to make sure you have all the information you need to proceed with your refund request. if you encounter any difficulties or have further questions, please don't hesitate to reach out to our customer support team. they are available {{customer support hours}} at {{toll-free number}} or through the live chat on our website at [company website url}}. we're here to help make your experience as smooth as possible. let me know if there's anything else i can help you with!\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 4.6582                  | CUDA        | 739.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  90%|█████████ | 45/50 [01:49<00:13,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 45/50 (Device: CUDA):\n",
      "Instruction: can you help me report troubles with payment?\n",
      "Generated Response: assuredly! i'm here to assist you in reporting any troubles you're facing with your payment. your feedback is incredibly valuable to us, and we want to ensure that we address your concerns promptly and effectively. to get started, could you please provide me with more details about the specific issues you encountered? this will help us better understand the situation and provide you with the most appropriate solution. thank you for reaching out and giving us the opportunity to resolve this matter for you.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.0736                  | CUDA        | 633.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  92%|█████████▏| 46/50 [01:52<00:10,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 46/50 (Device: CUDA):\n",
      "Instruction: i try to notify of an error with registrations\n",
      "Generated Response: i'm here to assist you in notifying us about the error you encountered during the registration process. your feedback is valuable to us, as it helps us identify areas for improvement and ensure a seamless experience for all our users. to provide you with the most accurate and effective support, could you please provide more details about what specific error occurred? this will enable us to investigate and address the issue promptly. thank you for bringing this to our attention, and rest assured, we are committed to resolving this matter for you as quickly as possible.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.5041                  | CUDA        | 643.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  94%|█████████▍| 47/50 [01:54<00:07,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 47/50 (Device: CUDA):\n",
      "Instruction: what do i have to do to cancel my platinum account?\n",
      "Generated Response: thank you for reaching out to us for assistance with canceling your {{account category}} account. i understand that you may have some questions or concerns regarding the cancellation process. rest assured, i'm here to guide you through the necessary steps and ensure a smooth cancellation experience. to proceed, could you please provide me with your account details, such as your username or email address, so that i can assist you further?\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.5211                  | CUDA        | 644.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  96%|█████████▌| 48/50 [01:56<00:04,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 48/50 (Device: CUDA):\n",
      "Instruction: how can i submit some feedback abot ur company\n",
      "Generated Response: i'll take care of it! i'm here to assist you in submitting feedback about our company. to submit your feedback, you can visit our website and navigate to the \"contact us\" or \"feedback\" section. there you will find a form or contact information that will guide you through the process. if you have any specific questions or need further assistance, please don't hesitate to let me know.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.8722                  | CUDA        | 623.6147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA:  98%|█████████▊| 49/50 [01:58<00:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 49/50 (Device: CUDA):\n",
      "Instruction: change  order ord-8335461\n",
      "Generated Response: i'm sorry to hear that you need to change order number {{order number}}. i understand how important it is for you to have control over your order. to assist you further, could you please provide me with more details about the specific changes you would like to make? this will help me guide you through the process and ensure that your request is handled promptly and accurately.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 1.8037                  | CUDA        | 617.3574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on CUDA: 100%|██████████| 50/50 [02:00<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 50/50 (Device: CUDA):\n",
      "Instruction: i need assistance to send some feedback for ur produucts\n",
      "Generated Response: thank you for reaching out! i'm here to assist you in sending your feedback about our products and services. your input is incredibly valuable to us as it helps us understand how we can better serve our customers. could you please provide me with more details about the specific product or service you would like to provide feedback on? this will allow me to guide you through the process and ensure that you receive the feedback you deserve.\n",
      "Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\n",
      "GPT2-Direct Gen     | 2.1332                  | CUDA        | 626.7354\n",
      "\n",
      "================================================================================\n",
      "BENCHMARK SUMMARY FOR CUDA\n",
      "================================================================================\n",
      "Average Generation Time: 2.4145 seconds\n",
      "Average Memory Usage: 634.2379 MB\n",
      "CPU results saved to performance_results_direct_cpu.json\n",
      "GPU results saved to performance_results_direct_gpu.json\n",
      "Performance log saved to direct_generation_performance_log.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance comparison plots saved to direct_generation_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "def log_to_file(message):\n",
    "    \"\"\"Helper function for logging\"\"\"\n",
    "    print(message)\n",
    "\n",
    "def generate_response(model, tokenizer, instruction, max_length=512, device=\"cuda\"):\n",
    "    \"\"\"Generate a response using GPT-2 model directly from instruction\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Create a prompt for generating response\n",
    "    input_text = f\"[INST] User query: {instruction}\\n\\nProvide a helpful customer service response: [RESP]\"\n",
    "\n",
    "    # Tokenize input\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "\n",
    "    try:\n",
    "        # Generate response\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=max_length,\n",
    "                num_beams=5,\n",
    "                no_repeat_ngram_size=2,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        # Decode the generated text\n",
    "        generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "\n",
    "        # Extract response part\n",
    "        if \"[RESP]\" in generated_text:\n",
    "            response = generated_text.split(\"[RESP]\")[1].strip()\n",
    "            # Clean up any trailing tokens\n",
    "            if \"[EOS]\" in response:\n",
    "                response = response.split(\"[EOS]\")[0].strip()\n",
    "        else:\n",
    "            # Fallback extraction\n",
    "            response = generated_text[len(input_text):].strip()\n",
    "            \n",
    "        # Format steps if present\n",
    "        steps_pattern = re.search(r'(\\d+)\\.\\s+([A-Z])', response)\n",
    "        if steps_pattern or \"step\" in response.lower() or \"follow\" in response.lower():\n",
    "            # Format steps to be on separate lines\n",
    "            for i in range(1, 10):\n",
    "                step_marker = f\"{i}. \"\n",
    "                if step_marker in response and f\"\\n{i}. \" not in response:\n",
    "                    response = response.replace(step_marker, f\"\\n{i}. \")\n",
    "\n",
    "            # Clean up any excess newlines\n",
    "            response = re.sub(r'\\n\\s*\\n', '\\n\\n', response)\n",
    "            response = response.lstrip('\\n')\n",
    "\n",
    "        # Clean any technical artifacts\n",
    "        response = re.sub(r'https?://\\S+', '', response)  # Remove URLs\n",
    "        response = re.sub(r'<[^>]*>', '', response)  # Remove HTML tags\n",
    "        response = re.sub(r'\\{\\s*\"[^\"]*\":', '', response)  # Remove JSON-like content\n",
    "        response = re.sub(r'\\s+', ' ', response).strip()  # Clean up whitespace\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate_response: {e}\")\n",
    "        return f\"I apologize, but I couldn't generate a response. Error: {str(e)}\"\n",
    "\n",
    "# Memory measurement functions\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024 / 1024  # Convert bytes to MB\n",
    "\n",
    "def get_peak_memory_usage(func, *args, **kwargs):\n",
    "    device_param = kwargs.pop('device', None)  # Remove device parameter before calling func\n",
    "    \n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    start_mem = get_memory_usage()\n",
    "    result = func(*args, **kwargs)  # Call without device parameter\n",
    "    end_mem = get_memory_usage()\n",
    "    \n",
    "    peak_gpu_mem = 0\n",
    "    if torch.cuda.is_available() and device_param == \"cuda\":\n",
    "        peak_gpu_mem = torch.cuda.max_memory_allocated() / 1024 / 1024  # MB\n",
    "        return result, peak_gpu_mem\n",
    "    else:\n",
    "        return result, max(0, end_mem - start_mem)\n",
    "\n",
    "class DirectGenerationPerformanceTest:\n",
    "    def __init__(self, model_paths, test_data_path, num_samples=50):\n",
    "        self.generation_model_path = model_paths[\"generation_model_path\"]\n",
    "        self.generation_tokenizer_path = model_paths[\"generation_tokenizer_path\"]\n",
    "        self.test_data_path = test_data_path\n",
    "        self.num_samples = num_samples\n",
    "        self.devices = [\"cpu\", \"cuda\"] if torch.cuda.is_available() else [\"cpu\"]\n",
    "        self.results = {device: [] for device in self.devices}\n",
    "        self.summary = {device: {\"generation_time\": [], \"memory_usage\": []} for device in self.devices}\n",
    "    \n",
    "    def load_models(self, device):\n",
    "        print(f\"\\nLoading models on {device.upper()}...\")\n",
    "        \n",
    "        # Load generation model using from_pretrained\n",
    "        try:\n",
    "            print(f\"Attempting to load generation model from {self.generation_model_path}\")\n",
    "            self.generation_model = GPT2LMHeadModel.from_pretrained(self.generation_model_path).to(device)\n",
    "            self.generation_tokenizer = GPT2Tokenizer.from_pretrained(self.generation_tokenizer_path)\n",
    "            self.generation_tokenizer.pad_token = self.generation_tokenizer.eos_token\n",
    "            self.generation_tokenizer.add_special_tokens({'additional_special_tokens': ['[INST]', '[RESP]', '[EOS]']})\n",
    "            self.generation_model.resize_token_embeddings(len(self.generation_tokenizer))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading generation model: {e}\")\n",
    "            print(\"Falling back to default GPT2...\")\n",
    "            self.generation_model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "            self.generation_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            self.generation_tokenizer.pad_token = self.generation_tokenizer.eos_token\n",
    "            self.generation_tokenizer.add_special_tokens({'additional_special_tokens': ['[INST]', '[RESP]', '[EOS]']})\n",
    "            self.generation_model.resize_token_embeddings(len(self.generation_tokenizer))\n",
    "        \n",
    "        self.generation_model.eval()\n",
    "        \n",
    "        return self.generation_model, self.generation_tokenizer\n",
    "    \n",
    "    def run_benchmark(self):\n",
    "        # Load test data\n",
    "        with open(self.test_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            test_data = json.load(f)\n",
    "            \n",
    "        # Select samples for testing\n",
    "        if len(test_data) > self.num_samples:\n",
    "            test_samples = test_data[:self.num_samples]\n",
    "        else:\n",
    "            test_samples = test_data\n",
    "            \n",
    "        print(f\"Running performance test on {len(test_samples)} samples\")\n",
    "        \n",
    "        # Run tests on each device\n",
    "        for device in self.devices:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"RUNNING BENCHMARK ON {device.upper()}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            generation_model, generation_tokenizer = self.load_models(device)\n",
    "            \n",
    "            for idx, sample in enumerate(tqdm(test_samples, desc=f\"Testing on {device.upper()}\")):\n",
    "                instruction = sample[\"instruction\"]\n",
    "                \n",
    "                # Measure generation time and memory\n",
    "                def run_generation():\n",
    "                    return generate_response(\n",
    "                        generation_model,\n",
    "                        generation_tokenizer,\n",
    "                        instruction,\n",
    "                        device=device\n",
    "                    )\n",
    "                \n",
    "                generation_start = time.time()\n",
    "                generated_response, generation_memory = get_peak_memory_usage(\n",
    "                    run_generation, device=device\n",
    "                )\n",
    "                generation_end = time.time()\n",
    "                generation_time = generation_end - generation_start\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    \"Model\": \"GPT2-Based Direct Generation\",\n",
    "                    \"Text Generation Time (s)\": generation_time,\n",
    "                    \"Device\": \"GPU\" if device == \"cuda\" else \"CPU\",\n",
    "                    \"Memory Usage (MB)\": generation_memory,\n",
    "                    \"Instruction\": instruction,\n",
    "                    \"Generated Response\": generated_response\n",
    "                }\n",
    "                self.results[device].append(result)\n",
    "                \n",
    "                # Update summary statistics\n",
    "                self.summary[device][\"generation_time\"].append(generation_time)\n",
    "                self.summary[device][\"memory_usage\"].append(generation_memory)\n",
    "                \n",
    "                # Print sample result\n",
    "                print(f\"\\nSample {idx+1}/{len(test_samples)} (Device: {device.upper()}):\")\n",
    "                print(f\"Instruction: {instruction}\")\n",
    "                print(f\"Generated Response: {generated_response}\")\n",
    "                print(f\"Model               | Text Generation Time (s)  | Device     | Memory Usage (MB)\")\n",
    "                print(f\"GPT2-Direct Gen     | {generation_time:.4f}                  | {device.upper()}        | {generation_memory:.4f}\")\n",
    "            \n",
    "            # Calculate average times\n",
    "            self.summary[device][\"avg_generation_time\"] = sum(self.summary[device][\"generation_time\"]) / len(test_samples)\n",
    "            self.summary[device][\"avg_memory_usage\"] = sum(self.summary[device][\"memory_usage\"]) / len(test_samples)\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"BENCHMARK SUMMARY FOR {device.upper()}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"Average Generation Time: {self.summary[device]['avg_generation_time']:.4f} seconds\")\n",
    "            print(f\"Average Memory Usage: {self.summary[device]['avg_memory_usage']:.4f} MB\")\n",
    "        \n",
    "        # Save results after all devices are tested\n",
    "        self.save_results()\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save benchmark results to JSON files in the specified format\"\"\"\n",
    "        \n",
    "        # Save CPU results\n",
    "        if \"cpu\" in self.devices and self.results[\"cpu\"]:\n",
    "            with open(\"performance_results_direct_cpu.json\", \"w\") as f:\n",
    "                json.dump(self.results[\"cpu\"], f, indent=4)\n",
    "            print(\"CPU results saved to performance_results_direct_cpu.json\")\n",
    "        \n",
    "        # Save GPU results\n",
    "        if \"cuda\" in self.devices and self.results[\"cuda\"]:\n",
    "            with open(\"performance_results_direct_gpu.json\", \"w\") as f:\n",
    "                json.dump(self.results[\"cuda\"], f, indent=4)\n",
    "            print(\"GPU results saved to performance_results_direct_gpu.json\")\n",
    "        \n",
    "        # Create performance log and comparison plots\n",
    "        self.create_performance_log()\n",
    "        if \"cpu\" in self.devices and \"cuda\" in self.devices:\n",
    "            self.create_comparison_plots()\n",
    "\n",
    "    def create_performance_log(self):\n",
    "        \"\"\"Create a text file with performance comparisons\"\"\"\n",
    "        with open(\"direct_generation_performance_log.txt\", \"w\") as f:\n",
    "            f.write(\"=== DIRECT GENERATION PERFORMANCE BENCHMARK RESULTS ===\\n\\n\")\n",
    "            \n",
    "            # Write CPU results\n",
    "            if \"cpu\" in self.devices:\n",
    "                f.write(\"CPU PERFORMANCE:\\n\")\n",
    "                f.write(f\"Average Generation Time: {self.summary['cpu']['avg_generation_time']:.4f} seconds\\n\")\n",
    "                f.write(f\"Average Memory Usage: {self.summary['cpu']['avg_memory_usage']:.4f} MB\\n\\n\")\n",
    "            \n",
    "            # Write GPU results\n",
    "            if \"cuda\" in self.devices:\n",
    "                f.write(\"GPU PERFORMANCE:\\n\")\n",
    "                f.write(f\"Average Generation Time: {self.summary['cuda']['avg_generation_time']:.4f} seconds\\n\")\n",
    "                f.write(f\"Average Memory Usage: {self.summary['cuda']['avg_memory_usage']:.4f} MB\\n\\n\")\n",
    "            \n",
    "            # Write comparison\n",
    "            if \"cpu\" in self.devices and \"cuda\" in self.devices:\n",
    "                f.write(\"CPU vs GPU COMPARISON:\\n\")\n",
    "                gen_speedup = self.summary['cpu']['avg_generation_time'] / self.summary['cuda']['avg_generation_time']\n",
    "                \n",
    "                f.write(f\"Generation Speed Improvement: {gen_speedup:.2f}x faster on GPU\\n\\n\")\n",
    "                \n",
    "                f.write(\"Notes:\\n\")\n",
    "                f.write(\"- GPU memory usage is typically higher but processing is faster\\n\")\n",
    "                f.write(\"- Direct generation without classification reduces overall processing time\\n\")\n",
    "            \n",
    "            f.write(\"\\n=== END OF REPORT ===\\n\")\n",
    "        \n",
    "        print(\"Performance log saved to direct_generation_performance_log.txt\")\n",
    "\n",
    "    def create_comparison_plots(self):\n",
    "        \"\"\"Create matplotlib comparison plots\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        if \"cpu\" not in self.devices or \"cuda\" not in self.devices:\n",
    "            print(\"Both CPU and GPU results are needed for comparison plots\")\n",
    "            return\n",
    "        \n",
    "        # Set up the plots\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # 1. Generation Time Comparison\n",
    "        plt.subplot(2, 1, 1)\n",
    "        \n",
    "        labels = ['Generation Time']\n",
    "        cpu_times = [self.summary['cpu']['avg_generation_time']]\n",
    "        gpu_times = [self.summary['cuda']['avg_generation_time']]\n",
    "        \n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, cpu_times, width, label='CPU')\n",
    "        plt.bar(x + width/2, gpu_times, width, label='GPU')\n",
    "        \n",
    "        plt.xlabel('Task')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.title('Average Generation Time Comparison')\n",
    "        plt.xticks(x, labels)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on the bars\n",
    "        for i, v in enumerate(cpu_times):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.2f}s\", ha='center')\n",
    "        \n",
    "        for i, v in enumerate(gpu_times):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.2f}s\", ha='center')\n",
    "        \n",
    "        # 2. Memory Usage\n",
    "        plt.subplot(2, 1, 2)\n",
    "        \n",
    "        memory_labels = ['CPU', 'GPU']\n",
    "        memory_usage = [self.summary['cpu']['avg_memory_usage'],\n",
    "                      self.summary['cuda']['avg_memory_usage']]\n",
    "        \n",
    "        plt.bar(memory_labels, memory_usage)\n",
    "        plt.xlabel('Device')\n",
    "        plt.ylabel('Memory Usage (MB)')\n",
    "        plt.title('Average Memory Usage')\n",
    "        \n",
    "        # Add memory usage labels\n",
    "        for i, v in enumerate(memory_usage):\n",
    "            plt.text(i, v + 0.1, f\"{v:.1f} MB\", ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('direct_generation_comparison.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Performance comparison plots saved to direct_generation_comparison.png\")\n",
    "\n",
    "def main():\n",
    "    # Define paths\n",
    "    model_paths = {\n",
    "        \"generation_model_path\": \"../../text_generation_results_03-09-25/model\",\n",
    "        \"generation_tokenizer_path\": \"../../text_generation_results_03-09-25/tokenizer\"\n",
    "    }\n",
    "    \n",
    "    test_data_path = \"../../test.json\"\n",
    "    \n",
    "    # Verify and print paths\n",
    "    print(f\"Test data path: {test_data_path}\")\n",
    "    \n",
    "    # Number of samples to test\n",
    "    num_samples = 50  # You can adjust this number\n",
    "    \n",
    "    # Run the benchmark\n",
    "    benchmark = DirectGenerationPerformanceTest(model_paths, test_data_path, num_samples)\n",
    "    benchmark.run_benchmark()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check available devices\n",
    "    # Check available devices\n",
    "    device_info = \"CUDA\" if torch.cuda.is_available() else \"CPU\"\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Running on: {device_info}\")\n",
    "    \n",
    "    # Run the benchmark\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
